{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TA(df):  \n",
    "    import talib\n",
    "    #報酬率\n",
    "    #1日\n",
    "    df[\"1_returns\"]=((df[\"Close\"])/(df[\"Close\"].shift())-1)*100\n",
    "    #5日\n",
    "    df[\"5_returns\"]=((df[\"Close\"])/(df[\"Close\"].shift(periods=5))-1)*100\n",
    "    #20日\n",
    "    df[\"20_returns\"]=((df[\"Close\"])/(df[\"Close\"].shift(periods=20))-1)*100\n",
    "\n",
    "    #動能指標MTM\n",
    "    #7\n",
    "    df[\"7momentum\"] = df[\"Close\"] - df[\"Close\"].shift(periods=7)\n",
    "    #14\n",
    "    df[\"14momentum\"] = df[\"Close\"] - df[\"Close\"].shift(periods=14)\n",
    "    #28\n",
    "    df[\"28momentum\"] = df[\"Close\"] - df[\"Close\"].shift(periods=28)\n",
    "\n",
    "    #簡單移動均線MA\n",
    "    #5\n",
    "    df[\"5ma\"] = df[\"Close\"].rolling(window =5).mean()\n",
    "    #10\n",
    "    df[\"10ma\"] = df[\"Close\"].rolling(window =10).mean()\n",
    "    #20\n",
    "    df[\"20ma\"] = df[\"Close\"].rolling(window =20).mean()\n",
    "\n",
    "    #指數移動均線EMA\n",
    "    #5\n",
    "    k = 2.0/(5+1)\n",
    "    df['5ema'] = df['Close']\n",
    "    df['5ema'] = (df['Close'] - df['5ema'].shift())*k + df['5ema'].shift()\n",
    "    #10\n",
    "    k = 2.0/(10+1)\n",
    "    df['10ema'] = df['Close']\n",
    "    df['10ema'] = (df['Close'] - df['10ema'].shift())*k + df['10ema'].shift()\n",
    "    #20\n",
    "    k = 2.0/(20+1)\n",
    "    df['20ema'] = df['Close']\n",
    "    df['20ema'] = (df['Close'] - df['20ema'].shift())*k + df['20ema'].shift()\n",
    "\n",
    "    #價格變動率RC\n",
    "    #5\n",
    "    df['5rc'] = (df['Close']-df[\"Close\"].shift(5)) / (df['Close'].shift(5))\n",
    "    #10\n",
    "    df['10rc'] = (df['Close']-df[\"Close\"].shift(10)) / (df['Close'].shift(10))\n",
    "    #20\n",
    "    df['20r '] = (df['Close']-df[\"Close\"].shift(20)) / (df['Close'].shift(20))\n",
    "\n",
    "    #布林通道\n",
    "    #布林通道上軌\n",
    "    df[\"10ma\"] = df[\"Close\"].rolling(window =10).mean()\n",
    "    df[\"bollinger_upper\"]= 2*df['Close'].rolling(window =10).std() + df['10ma']\n",
    "    #布林通道下軌\n",
    "    df[\"bollinger_lower\"]= df['10ma']-2*df['Close'].rolling(window =10).std()\n",
    "\n",
    "    #KD指標\n",
    "    #RSV\n",
    "    df[\"RSV\"]=((df[\"Close\"]-df[\"Low\"].rolling(window=9).min())/(df[\"High\"].rolling(window=9).max()-df[\"Low\"].rolling(window=9).min()))*100\n",
    "    fastk,fastd=talib.STOCH(df[\"High\"],df[\"Low\"],df[\"Close\"],9,3)\n",
    "    #K\n",
    "    df[\"K\"]=fastk\n",
    "    df[\"D\"]=fastd\n",
    "\n",
    "    #MACD\n",
    "    df['ema_M'] = df['Close']\n",
    "    df['ema_M'] = (df['Close'] - df['ema_M'].shift())*0.1528 + df['ema_M'].shift()\n",
    "    df['ema_L'] = df['Close']\n",
    "    df['ema_L'] = (df['Close'] - df['ema_L'].shift())*0.0741 + df['ema_L'].shift()\n",
    "    df[\"DIF\"]=df[\"ema_L\"]-df[\"ema_M\"]\n",
    "    df.drop(columns=[\"ema_M\",\"ema_L\"],axis=1,inplace=True)\n",
    "\n",
    "    #Pivot Point\n",
    "    #典型\n",
    "    df_temp = df.shift()\n",
    "    df[\"classic_pp\"]=(df_temp[\"High\"]+df_temp[\"Low\"]+df_temp[\"Close\"])/3\n",
    "    #woodie\n",
    "    df['woodie_pp'] = ( df_temp['High'] + df_temp['Low'] + df_temp['Close']*2)/4.0\n",
    "\n",
    "    # 14日ATR\n",
    "    df['14atr'] = df['High'] - df['Low']\n",
    "    df['14atr'] = (df[\"14atr\"].rolling(14).sum())/14\n",
    "\n",
    "     #RSI指標\n",
    "    df['shift']=df['Close'].shift()\n",
    "    df['gain']=df['Close']-df['shift']\n",
    "    df.loc[df['gain'] < 0,'gain']=0\n",
    "    df['loss']=df['shift']-df['Close']\n",
    "    df.loc[df['loss'] <= 0,'loss']=0\n",
    "    df[\"6_rsi\"]=(df[\"gain\"].rolling(6).sum())/(df[\"gain\"].rolling(6).sum()+df[\"loss\"].rolling(6).sum())*100\n",
    "    df[\"12_rsi\"]=(df[\"gain\"].rolling(12).sum())/(df[\"gain\"].rolling(12).sum()+df[\"loss\"].rolling(12).sum())*100\n",
    "    df.drop(['shift','gain','loss',],axis=1,inplace=True)\n",
    "\n",
    "    #W%R 威廉指標\n",
    "    #14\n",
    "    df[\"14_wr\"]=((df[\"High\"].rolling(window=14).max()-df[\"Close\"])/((df[\"High\"].rolling(window=14).max())-(df[\"Low\"].rolling(window=14).min())))*100\n",
    "\n",
    "    #7日黃金分割線\n",
    "    high = df['Close'].rolling(window=7).max()\n",
    "    low = df['Close'].rolling(window=7).min()\n",
    "    df['uptrend_7day_fibo_0.382'] = high - ((high-low)*0.382)\n",
    "    df['downtrend_7day_fibo_0.382'] = low + ((high-low)*0.382)\n",
    "    df['uptrend_7day_fibo_0.5'] = high - ((high-low)*0.5)\n",
    "    df['downtrend_7day_fibo_0.5'] = low + ((high-low)*0.5)\n",
    "    df['uptrend_7day_fibo_0.618'] = high - ((high-low)*0.618)\n",
    "    df['downtrend_7day_fibo_0.618'] = low + ((high-low)*0.618)\n",
    "    #28日黃金分割線\n",
    "    high = df['Close'].rolling(window=28).max()\n",
    "    low = df['Close'].rolling(window=28).min()\n",
    "    df['uptrend_28day_fibo_0.382'] = high - ((high-low)*0.382)\n",
    "    df['downtrend_28day_fibo_0.382'] = low + ((high-low)*0.382)\n",
    "    df['uptrend_28day_fibo_0.5'] = high - ((high-low)*0.5)\n",
    "    df['downtrend_28day_fibo_0.5'] = low + ((high-low)*0.5)\n",
    "    df['uptrend_28day_fibo_0.618'] = high - ((high-low)*0.618)\n",
    "    df['downtrend_28day_fibo_0.618'] = low + ((high-low)*0.618)\n",
    "\n",
    "    #BIAS\n",
    "    #5、10、20\n",
    "    df[\"5_bias\"]=((df[\"Close\"]-df[\"5ma\"])/df[\"5ma\"])*100\n",
    "    df[\"10_bias\"]=((df[\"Close\"]-df[\"10ma\"])/df[\"10ma\"])*100\n",
    "    df[\"20_bias\"]=((df[\"Close\"]-df[\"20ma\"])/df[\"20ma\"])*100\n",
    "\n",
    "     #PSY心理線\n",
    "    df[\"up\"]=df[\"Close\"]-df[\"Close\"].shift()\n",
    "    df.loc[df[\"up\"]>0,\"up\"]=1\n",
    "    df.loc[df[\"up\"]<=0,\"up\"]=0\n",
    "    df[\"psy\"]=(df[\"up\"].rolling(window=10).sum()/10)*100\n",
    "    df.drop([\"up\"],axis=1,inplace=True)\n",
    "\n",
    "    #OBV指標\n",
    "    df['positive_signed_volume'] = df[df['1_returns'] >0]['Volume']\n",
    "    df['positive_signed_volume'].replace(float('nan'),0,inplace=True)\n",
    "    df['negative_signed_volume'] = df[df['1_returns'] < 0]['Volume']*(-1.0)\n",
    "    df['negative_signed_volume'].replace(float('nan'),0,inplace=True)\n",
    "    df['signed_volume'] = df['positive_signed_volume'] + df['negative_signed_volume']\n",
    "    df['5_obv'] = (df['signed_volume'].rolling(window=5).sum())\n",
    "    df['10_obv'] = (df['signed_volume'].rolling(window=10).sum())\n",
    "    df['20_obv'] = (df['signed_volume'].rolling(window=20).sum())\n",
    "\n",
    "    #VR\n",
    "    df['negative_signed_volume']=df['negative_signed_volume']*(-1.0)\n",
    "    df[\"vr\"]=((df[\"positive_signed_volume\"].rolling(10).sum()+0.5*df[\"Volume\"].rolling(10).sum())/(df[\"negative_signed_volume\"].rolling(10).sum()+0.5*df[\"Volume\"].rolling(10).sum()))*100\n",
    "    df.drop(['signed_volume','positive_signed_volume',\"negative_signed_volume\"],axis = 1,inplace=True)\n",
    "\n",
    "    #CCI\n",
    "    df[\"TP\"]=(df[\"High\"]+df[\"Low\"]+df[\"Close\"])/3\n",
    "    df[\"avgTP\"]=(df[\"TP\"].rolling(14).sum())/14\n",
    "    df[\"MD\"]=abs(df[\"TP\"]-df[\"avgTP\"])\n",
    "    df[\"avgMD\"]=((df[\"MD\"].rolling(14).sum())/14)*0.015\n",
    "    df[\"CCI\"]=(df[\"TP\"]-df[\"avgTP\"])/df[\"avgMD\"]\n",
    "    df.drop([\"TP\",\"avgTP\",\"MD\",\"avgMD\"],axis=1,inplace=True)\n",
    "    \n",
    "    #CDP\n",
    "    df[\"cdp_AH\"]=df[\"woodie_pp\"]+(df_temp[\"High\"]-df_temp[\"Low\"])\n",
    "    df[\"cdp_NH\"]=df[\"woodie_pp\"]*2-df_temp[\"Low\"]\n",
    "    df[\"cdp_AL\"]=df[\"woodie_pp\"]-(df_temp[\"High\"]-df_temp[\"Low\"])\n",
    "    df[\"cdp_NL\"]=df[\"woodie_pp\"]*2-df_temp[\"High\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def afterTA(df,days):\n",
    "    #把na值刪掉\n",
    "    df.dropna(inplace=True)\n",
    "    #預測後幾天的收盤價\n",
    "    Target=df[\"Close\"].shift(-1*days)\n",
    "    #清理na值\n",
    "    Target.dropna(inplace=True)\n",
    "    #df後幾天的資料不要\n",
    "    df=df.drop(df.index[-1*days:])\n",
    "    return Target,df\n",
    "\n",
    "def afterTA(df,days):\n",
    "    #把na值刪掉\n",
    "    df.dropna(inplace=True)\n",
    "    #預測後幾天的收盤價\n",
    "    Target=df[\"Close\"].shift(-1*days)\n",
    "    #清理na值\n",
    "    Target.dropna(inplace=True)\n",
    "    #df後幾天的資料不要\n",
    "    df=df.drop(df.index[-1*days:])\n",
    "    return Target,df\n",
    "\n",
    "#將feature_df_transformed分成訓練跟測試集\n",
    "def traintest(df,Target,train_ratio,Open):\n",
    "    #分出訓練、測試期間\n",
    "    #將訓練跟測試期分比例\n",
    "    train_num=round(len(df)*train_ratio)\n",
    "    #訓練期\n",
    "    train_df=df[:train_num]\n",
    "    train_target=Target[:train_num]\n",
    "    #測試期\n",
    "    test_df=df[train_num:]\n",
    "    test_target=Target[train_num:]\n",
    "    Open_target=Open[train_num:]\n",
    "    Open_target.dropna(inplace=True)\n",
    "    return train_df,train_target,test_df,test_target,Open_target\n",
    "\n",
    "#批次標準化def\n",
    "def batchnormalization(data):\n",
    "    import tensorflow as tf\n",
    "    w=tf.constant(data.tolist())\n",
    "    mean,var=tf.nn.moments(w,[0])\n",
    "    offset=0\n",
    "    scale=1\n",
    "    epsilon=1e-8\n",
    "    a=tf.nn.batch_normalization(w,mean,var,offset,scale,epsilon,name=None)\n",
    "    return a\n",
    "\n",
    "#資料分集\n",
    "def dataset_batch(train_df,train_target,splits,test_df,test_target):\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    X=np.array(train_df)\n",
    "    y=np.array(train_target)\n",
    "    #使用時間序列分割\n",
    "    tscv=TimeSeriesSplit(n_splits=splits)\n",
    "    X_train=[]\n",
    "    X_validation=[]\n",
    "    y_train=[]\n",
    "    y_validation=[]\n",
    "    for train_index, validation_index in tscv.split(X):\n",
    "        X_train.append(pd.DataFrame(X[train_index]).apply(lambda x:((x-x.mean())/(x.max()-x.min()))))\n",
    "        X_validation.append(pd.DataFrame(X[validation_index]).apply(lambda x:((x-x.mean())/(x.max()-x.min()))))\n",
    "        y_train.append(pd.DataFrame(y[train_index]).apply(lambda x:((x-x.mean())/(x.max()-x.min()))))\n",
    "        y_validation.append(pd.DataFrame(y[validation_index]).apply(lambda x:((x-x.mean())/(x.max()-x.min()))))\n",
    "\n",
    "\n",
    "    #test_df跟整的train_df做批次標準化\n",
    "    X_test=pd.DataFrame(test_df).apply(lambda x:((x-x.mean())/(x.max()-x.min())))\n",
    "    y_test=pd.DataFrame(test_target).apply(lambda x:((x-x.mean())/(x.max()-x.min())))\n",
    "    all_X_train=pd.DataFrame(train_df).apply(lambda x:((x-x.mean())/(x.max()-x.min())))\n",
    "    all_y_train=pd.DataFrame(train_target).apply(lambda x:((x-x.mean())/(x.max()-x.min())))\n",
    "    return X_train,X_validation,y_train,y_validation,X_test,y_test,all_X_train,all_y_train\n",
    "\n",
    "#找出最佳參數\n",
    "def bestscore(X_train,y_train,X_validation,y_validation,opt):\n",
    "    from sklearn.svm import SVR\n",
    "    #最佳化參數\n",
    "    opt.fit(X_train,y_train)\n",
    "    optscore=opt.score(X_validation, y_validation)\n",
    "    optparams=opt.best_params_\n",
    "    #比較組別\n",
    "    #原始SVR\n",
    "    svr=SVR()\n",
    "    svr.fit(X_train,y_train)\n",
    "    svrscore=svr.score(X_validation,y_validation)\n",
    "    return optscore,optparams,svrscore\n",
    "\n",
    "#找出最佳組合於clfs\n",
    "#clftodf,最佳組合,最佳化最大值,最佳平均值\n",
    "def clfs(optscore,optparams,svrscore):\n",
    "    import pandas as pd\n",
    "    #找出最大值的位置及組合\n",
    "    clfs=pd.DataFrame()\n",
    "    clfs[\"OPT\"]=optscore\n",
    "    clfs[\"SVR\"]=svrscore\n",
    "    clfs[\"n_iter\"]=[1,2,3,4,5]\n",
    "    #最佳參數組合\n",
    "    optmax=optparams[clfs[\"OPT\"].idxmax()]\n",
    "    return clfs,optmax,clfs[\"OPT\"].max(),clfs[\"OPT\"].mean()\n",
    "\n",
    "#計算交易策略\n",
    "def resdf(startday,endday,sillnum,days,test_target,y_test,testsvr,X_test,current,Open_target,testtime):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_log_error,r2_score\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    temp=pd.DataFrame()\n",
    "    temp[\"time\"]=test_target.index\n",
    "    #當天實際收盤價_正規化\n",
    "    temp[\"today_c_nor\"]=list(pd.DataFrame(current).apply(lambda x:((x-x.mean())/(x.max()-x.min())))[\"Close\"])\n",
    "    #SVR預測值\n",
    "    temp[\"pre_c_nor\"]=testsvr.predict(X_test)\n",
    "    #當天實際收盤價\n",
    "    temp[\"today_c\"]=list(current)\n",
    "    #實際未來開盤價\n",
    "    temp[\"tomorrow_o\"]=list(Open_target)\n",
    "    #實際未來收盤價\n",
    "    temp[\"tomorrow_c\"]=list(test_target)\n",
    "    #實際未來收盤價_正規化\n",
    "    temp[\"tomorrow_c_nor\"]=list(y_test[\"Close\"])\n",
    "    #分期間(整個,平穩，動盪)\n",
    "    temp=temp[temp[\"time\"].between(startday,endday)]\n",
    "\n",
    "    cost=(0.1425*0.6+0.1425*0.6+0.3*0.5)/100\n",
    "    a=temp[temp[\"pre_c_nor\"]>temp[\"today_c_nor\"]]\n",
    "    a=a[a[\"tomorrow_o\"]<a[\"today_c\"]*(1-cost-sillnum)]\n",
    "    a[\"profit_cost\"]=((a[\"tomorrow_c\"]-a[\"tomorrow_o\"])/a[\"tomorrow_o\"])-cost\n",
    "    a[\"profit\"]=((a[\"tomorrow_c\"]-a[\"tomorrow_o\"])/a[\"tomorrow_o\"])\n",
    "\n",
    "    resdf_out=pd.DataFrame(index=[testtime])\n",
    "    resdf_out[\"年化報酬率_有\"]=a.profit_cost.sum()*250/len(temp)\n",
    "    resdf_out[\"年化報酬率_無\"]=a.profit.sum()*250/len(temp)\n",
    "    if len(a)>0:\n",
    "        resdf_out[\"年化報酬率_有_勝率\"]=len(a[a[\"profit_cost\"]>0])/len(a)\n",
    "        resdf_out[\"年化報酬率_無_勝率\"]=len(a[a[\"profit\"]>0])/len(a)\n",
    "    else:\n",
    "        resdf_out[\"年化報酬率_有_勝率\"]=\"無\"\n",
    "        resdf_out[\"年化報酬率_無_勝率\"]=\"無\"\n",
    "    resdf_out[\"交易次數\"]=len(a)\n",
    "    temp=temp.reset_index()\n",
    "    resdf_out[\"BandH\"]=((temp[\"tomorrow_c\"][len(temp)-1]-temp[\"tomorrow_c\"][0])/temp[\"tomorrow_c\"][0])    \n",
    "    resdf_out[\"r_square\"]=round(r2_score(temp[\"tomorrow_c_nor\"],temp[\"pre_c_nor\"]),4)\n",
    "    resdf_out[\"MAE\"]=round(mean_absolute_error(temp[\"tomorrow_c_nor\"],temp[\"pre_c_nor\"]),4)\n",
    "    resdf_out[\"MSE\"]=round(mean_squared_error(temp[\"tomorrow_c_nor\"],temp[\"pre_c_nor\"]),4)\n",
    "    return resdf_out,temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_log_error,r2_score\n",
    "import time\n",
    "from sklearn.cross_decomposition import CCA\n",
    "#從38公司裡取檔到pathlist\n",
    "pathlist=[]\n",
    "for dirPath, dirNames, fileNames in os.walk(r\"C:\\Users\\ina\\Desktop\\excel\"):\n",
    "    for f in fileNames:\n",
    "        pathlist.append(os.path.join(dirPath, f))\n",
    "#預測天數\n",
    "days=1\n",
    "#時間序列分割\n",
    "splits=5\n",
    "#超參數優化迭代次數\n",
    "n_iter=10\n",
    "#超參數優化模型和參數設置\n",
    "opt=BayesSearchCV(\n",
    "        SVR(),\n",
    "        {\n",
    "        \"kernel\":(\"linear\",\"rbf\",\"sigmoid\",\"poly\"),\n",
    "        \"degree\":(1,10),\n",
    "        \"gamma\":(1e-9,1.0,\"log-uniform\"),\n",
    "        \"C\":(1,10)\n",
    "        },\n",
    "        scoring=\"r2\",\n",
    "        n_iter=n_iter,\n",
    "        cv=TimeSeriesSplit(n_splits=5),\n",
    "        refit=True,\n",
    "        return_train_score=True\n",
    ")\n",
    "#模型名稱\n",
    "modelname=\"FA_CCA_SVR\"\n",
    "#交易策略門檻值\n",
    "sillnum=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for excel in pathlist:\n",
    "    df=pd.read_excel(excel,index_col=0)\n",
    "    #將日期設置為index\n",
    "    companyname=excel[27:-5]\n",
    "    print(companyname)\n",
    "    #開始日期\n",
    "    start=\"2015-01-01\"\n",
    "    #結束日期\n",
    "    df=df[df.index>start]\n",
    "    #分成技術面跟籌碼面\n",
    "    ta_df=df[df.columns[0:5]]\n",
    "    chip_df=df[df.columns[5:]]\n",
    "    chip_df[\"Close\"]=df[\"Close\"]\n",
    "    \n",
    "    #def\n",
    "    #匯入技術指標\n",
    "    ta_data=TA(ta_df)\n",
    "\n",
    "    #將ta_data分成Target跟feature_df\n",
    "    #分別將ta_df和chip_df匯入\n",
    "    #使用afterTA把空值刪除掉\n",
    "    ta_Target,ta_feature_df=afterTA(ta_data,days)\n",
    "    chip_Target,chip_feature_df=afterTA(chip_df,days)\n",
    "    \n",
    "    #取出當天收盤價\n",
    "    current=ta_feature_df[\"Close\"][round(len(ta_feature_df)*0.8):]\n",
    "    \n",
    "    #取出隔一天開盤價\n",
    "    openprice=ta_data.dropna()[\"Open\"].shift(-1*days)\n",
    "    \n",
    "    #把chip_target和chip_feature_df長度縮短跟ta長度一樣\n",
    "    diffdate=list(set(chip_Target.keys()).difference(set(ta_Target.keys())))\n",
    "    chip_feature_df=chip_feature_df.drop(diffdate)\n",
    "    chip_Target=chip_Target.drop(diffdate)\n",
    "\n",
    "    #找出ta_feature_df的相關性\n",
    "    a=ta_feature_df.corrwith(ta_Target,method=\"spearman\")\n",
    "    #由小到大排序相關性排行\n",
    "    a=list(a.sort_values().index)\n",
    "    #要選擇因素數量(Kaiser準則)\n",
    "    ta_fa=FactorAnalyzer(rotation=None)\n",
    "    #for 迴圈測試沒有奇異矩陣\n",
    "    ta_dfnum=[j for j in range(0,len(a))]\n",
    "    for i in range(0,len(a)):\n",
    "        test=ta_feature_df.drop(columns=a[:i],axis=1)\n",
    "        try:\n",
    "            ta_fa.fit(test)\n",
    "        except np.linalg.LinAlgError as err:\n",
    "            if  \"Singular matrix\" in str(err):\n",
    "                ta_dfnum.remove(i)\n",
    "    ta_feature_df.drop(columns=a[:ta_dfnum[0]],axis=1,inplace=True)\n",
    "    chip_feature_df.drop(\"Close\",axis=1,inplace=True) \n",
    "\n",
    "\n",
    "    #找出chip_feature_df的相關性\n",
    "    b=chip_feature_df.corrwith(ta_Target,method=\"spearman\")\n",
    "    #由小到大排序相關性排行\n",
    "    b=list(b.sort_values().index)\n",
    "    #要選擇因素數量(Kaiser準則)\n",
    "    chip_fa=FactorAnalyzer(rotation=None)\n",
    "    #for 迴圈測試沒有奇異矩陣\n",
    "    chip_dfnum=[j for j in range(0,len(b))]\n",
    "    for i in range(0,len(b)):\n",
    "        test=chip_feature_df.drop(columns=b[:i],axis=1)\n",
    "        try:\n",
    "            chip_fa.fit(test)\n",
    "        except np.linalg.LinAlgError as err:\n",
    "            if  \"Singular matrix\" in str(err):\n",
    "                chip_dfnum.remove(i)\n",
    "    chip_feature_df.drop(columns=b[:chip_dfnum[0]],axis=1,inplace=True)\n",
    "    \n",
    "    #ta_FA\n",
    "    ta_FA=FactorAnalysis()\n",
    "    #將FA投射到新樣本\n",
    "    #並將array轉為df以利訓練跟測試分集\n",
    "    ta_feature_df_transformed=pd.DataFrame(ta_FA.fit_transform(ta_feature_df))\n",
    "    #chip_FA\n",
    "    chip_FA=FactorAnalysis()\n",
    "    #將FA投射到新樣本\n",
    "    #並將array轉為df以利訓練跟測試分集\n",
    "    chip_feature_df_transformed=pd.DataFrame(chip_FA.fit_transform(chip_feature_df))\n",
    "\n",
    "    #合併特徵檔\n",
    "    two_df=pd.concat([ta_feature_df_transformed,chip_feature_df_transformed],axis=1,ignore_index=True,)\n",
    "\n",
    "    #CCA特徵融合\n",
    "    cca=CCA(n_components=1)\n",
    "    #X值為合併特徵檔，Y值為這段期間收盤價\n",
    "    cca.fit(two_df,chip_Target)\n",
    "    cca_two_df,cca_Target=cca.transform(two_df,ta_Target)\n",
    "\n",
    "    # 資料分集和批次標準化\n",
    "    # 先分出訓練和測試期，再將訓練期分成訓練和驗證期，在逐一批次標準化\n",
    "    train_df,train_target,test_df,test_target,Open_target=traintest(cca_two_df,ta_Target,0.8,openprice)\n",
    "    X_train,X_validation,y_train,y_validation,X_test,y_test,all_X_train,all_y_train=dataset_batch(train_df,train_target,splits,test_df,test_target)\n",
    "    \n",
    "    #找出最佳參數\n",
    "    optscorelist=[]\n",
    "    optparamslist=[]\n",
    "    svrscorelist=[]\n",
    "    DRscorelist=[]\n",
    "    #將timeseriessplit次數導入超參數優化模型\n",
    "    for i in range(0,len(X_train)):\n",
    "        optscore,optparams,svrscore=bestscore(X_train[i],y_train[i],X_validation[i],y_validation[i],opt)\n",
    "        #超參數最佳化數值\n",
    "        optscorelist.append(optscore)\n",
    "        #超參數最佳化組合\n",
    "        optparamslist.append(optparams)\n",
    "        #普通SVR數值\n",
    "        svrscorelist.append(svrscore)\n",
    "\n",
    "    #找出最佳組合於clfs\n",
    "    #clftodf,最佳組合,最佳化最大值,最佳平均值\n",
    "    clfs_df,optmax,paramsmax,paramsmean=clfs(optscorelist,optparamslist,svrscorelist)\n",
    "\n",
    "    #將最佳參數組合套用在測試期\n",
    "    testsvr=SVR(C=optmax.get(\"C\"),\n",
    "    degree=optmax.get(\"degree\"),\n",
    "    gamma=optmax.get(\"gamma\"),\n",
    "    kernel=optmax.get(\"kernel\")).fit(all_X_train,all_y_train)\n",
    "\n",
    "\n",
    "    #不同時期計算損益\n",
    "    entire,entire_detail=resdf(test_target.index[0],\"2020-03-30\",sillnum,days,test_target,y_test,testsvr,X_test,current,Open_target,\"entire\")\n",
    "    safe,safe_detail=resdf(test_target.index[0],\"2019-11-30\",sillnum,days,test_target,y_test,testsvr,X_test,current,Open_target,\"safe\")\n",
    "    bad,bad_detail=resdf(\"2019-12-01\",\"2020-03-30\",sillnum,days,test_target,y_test,testsvr,X_test,current,Open_target,\"bad\")\n",
    "\n",
    "    #把所有結果顯示同張表\n",
    "    concat_df=safe\n",
    "    for a in [bad,entire]:\n",
    "        concat_df=concat_df.append(a)\n",
    "     \n",
    "    print(\"整個時期有成本之年化報酬率\",round(concat_df.iat[2,0]*100,2),\"%\")\n",
    "    print(\"完成\",companyname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
